{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c37a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c2401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T03:29:07.929398Z",
     "iopub.status.busy": "2024-04-14T03:29:07.928579Z",
     "iopub.status.idle": "2024-04-14T03:29:15.268925Z",
     "shell.execute_reply": "2024-04-14T03:29:15.267173Z"
    },
    "papermill": {
     "duration": 7.353837,
     "end_time": "2024-04-14T03:29:15.271688",
     "exception": false,
     "start_time": "2024-04-14T03:29:07.917851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Begin by importing the basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "\n",
    "#I have a few warnings I don't want to clutter the markdown file with\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#Next read in the dataset\n",
    "demand_df = pd.read_csv(\"../assets/base-historical-product-demand.csv\")\n",
    "\n",
    "#View the first 3 rows of the data, to see what it looks like\n",
    "demand_df.head(3)\n",
    "\n",
    "# determine the statistical details of the numerical values\n",
    "print(demand_df.describe())\n",
    "\n",
    "#What is the missing values in each of the columns\n",
    "print(demand_df.isnull().sum())\n",
    "\n",
    "#Remove null values from the date column\n",
    "demand_df = demand_df[demand_df['Date'].notnull()]\n",
    "\n",
    "# Find the minimum and maximum dates\n",
    "min_date = demand_df['Date'].min()\n",
    "max_date = demand_df['Date'].max()\n",
    "\n",
    "print(f\"The earliest date is: {min_date}\")\n",
    "print(f\"The latest date is: {max_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1715b06e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T03:29:15.307338Z",
     "iopub.status.busy": "2024-04-14T03:29:15.306911Z",
     "iopub.status.idle": "2024-04-14T03:29:22.362023Z",
     "shell.execute_reply": "2024-04-14T03:29:22.360380Z"
    },
    "papermill": {
     "duration": 7.069126,
     "end_time": "2024-04-14T03:29:22.366136",
     "exception": false,
     "start_time": "2024-04-14T03:29:15.297010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Before we can begin visualizing, a few changes need to occur, like data types and groupings\n",
    "#This will allow our visuals to populate quicker\n",
    "\n",
    "#Make sure Order_demand is read in as a numeric datatype\n",
    "print(demand_df['Order_Demand'].dtypes)\n",
    "\n",
    "#Need to change the date to a date datatype from an object\n",
    "demand_df['Date'] = pd.to_datetime(demand_df['Date'])\n",
    "demand_df['Order_Demand'] = pd.to_numeric(demand_df['Order_Demand'], errors='coerce')\n",
    "\n",
    "#Finally Grouping\n",
    "demand_df['Date'] = pd.to_datetime(demand_df['Date'])\n",
    "demand_df_group = demand_df.groupby(pd.Grouper(key='Date', freq='M'))['Order_Demand'].sum().reset_index()\n",
    "\n",
    "#Plot the new dataset\n",
    "sns.set_style(\"whitegrid\") #Set tje style\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=demand_df_group, x='Date', y='Order_Demand', color = '#18B15A')\n",
    "plt.title('Order Demand Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Order Demand')\n",
    "plt.show()\n",
    "\n",
    "#Now that we see the overall plot, we notice that any dates prior to 2012 are going\n",
    "#to be irrelevant. We can remove these values\n",
    "print(demand_df.head())\n",
    "\n",
    "#Now that we see the overall plot, we notice that any dates prior to 2012 are going\n",
    "#to be irrelevant. We can remove these values\n",
    "demand_df = demand_df[demand_df['Date']>'2011-12-31']\n",
    "\n",
    "#Lets see what this looks like grouped by warehouse, to understand which of our warehouses receive the most demand\n",
    "demand_df_group_warehouse = demand_df.groupby(['Date', 'Warehouse'])['Order_Demand'].sum().reset_index()\n",
    "\n",
    "#Plot this faceted now\n",
    "#Found out I need to use sns.relplot, as lineplot does not read facets well\n",
    "g = sns.relplot(data=demand_df_group_warehouse, \n",
    "                x='Date', \n",
    "                y='Order_Demand', \n",
    "                kind=\"line\",\n",
    "                hue='Warehouse',\n",
    "                palette=[\"#EF9A9A\", \"#673AB7\", \"#039BE5\", \"#FB8C00\"],\n",
    "                col='Warehouse',  # Facet by 'Warehouse'\n",
    "                col_wrap=2,  \n",
    "                height=3, aspect=1.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41943c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T03:29:22.419138Z",
     "iopub.status.busy": "2024-04-14T03:29:22.418117Z",
     "iopub.status.idle": "2024-04-14T03:29:30.411122Z",
     "shell.execute_reply": "2024-04-14T03:29:30.409780Z"
    },
    "papermill": {
     "duration": 8.010727,
     "end_time": "2024-04-14T03:29:30.414023",
     "exception": false,
     "start_time": "2024-04-14T03:29:22.403296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We will begin by breaking each warehouse into its own dataframe\n",
    "whse_s_df = demand_df[demand_df['Warehouse']=='Whse_S']\n",
    "whse_a_df = demand_df[demand_df['Warehouse']=='Whse_A']\n",
    "whse_c_df = demand_df[demand_df['Warehouse']=='Whse_C']\n",
    "whse_j_df = demand_df[demand_df['Warehouse']=='Whse_J']\n",
    "\n",
    "#Now we can begin looking at the product category of the demand\n",
    "whse_s_df_group_category = whse_s_df.groupby(['Date', 'Product_Category'])['Order_Demand'].sum().reset_index().sort_values('Order_Demand', ascending=False)\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=whse_s_df_group_category, x='Product_Category', y='Order_Demand', color =\"#EF9A9A\")\n",
    "plt.title('Warehouse S Product Demand')\n",
    "plt.xlabel('Product Category')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Product Demand')\n",
    "plt.show()\n",
    "\n",
    "#Rinse and repeat for all of the other datatypes\n",
    "whse_a_df_group_category = whse_a_df.groupby(['Date', 'Product_Category'])['Order_Demand'].sum().reset_index().sort_values('Order_Demand', ascending=False)\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=whse_a_df_group_category, x='Product_Category', y='Order_Demand', color =\"#673AB7\")\n",
    "plt.title('Warehouse A Product Demand')\n",
    "plt.xlabel('Product Category')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Product Demand')\n",
    "plt.show()\n",
    "\n",
    "whse_c_df_group_category = whse_c_df.groupby(['Date', 'Product_Category'])['Order_Demand'].sum().reset_index().sort_values('Order_Demand', ascending=False)\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=whse_c_df_group_category, x='Product_Category', y='Order_Demand', color =\"#039BE5\")\n",
    "plt.title('Warehouse C Product Demand')\n",
    "plt.xlabel('Product Category')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Product Demand')\n",
    "plt.show()\n",
    "\n",
    "whse_j_df_group_category = whse_j_df.groupby(['Date', 'Product_Category'])['Order_Demand'].sum().reset_index().sort_values('Order_Demand', ascending=False)\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=whse_j_df_group_category, x='Product_Category', y='Order_Demand', color =\"#FB8C00\")\n",
    "plt.title('Warehouse J Product Demand')\n",
    "plt.xlabel('Product Category')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Product Demand')\n",
    "plt.show()\n",
    "\n",
    "#Now before building out the demand forecast, lets go ahead and isolate product 19 at the largest warehouse\n",
    "whse_j_df_cat_19 = whse_j_df[whse_j_df['Product_Category']=='Category_019']\n",
    "whse_j_df_cat_19_group = whse_j_df_cat_19.groupby(pd.Grouper(key='Date', freq='M'))['Order_Demand'].sum().reset_index()\n",
    "\n",
    "sns.set_style(\"whitegrid\") #Set tje style\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=whse_j_df_cat_19_group, x='Date', y='Order_Demand', color = '#FB8C00')\n",
    "plt.title('Warehouse J Category 19 Demand Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Order Demand')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647902e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T03:29:30.481837Z",
     "iopub.status.busy": "2024-04-14T03:29:30.480217Z",
     "iopub.status.idle": "2024-04-14T03:29:31.120873Z",
     "shell.execute_reply": "2024-04-14T03:29:31.119079Z"
    },
    "papermill": {
     "duration": 0.662719,
     "end_time": "2024-04-14T03:29:31.124871",
     "exception": false,
     "start_time": "2024-04-14T03:29:30.462152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Build the data we will work with from the original data structure to give us more points\n",
    "category_19_df = demand_df[(demand_df['Warehouse'] == 'Whse_J') & (demand_df['Product_Category'] == 'Category_019')]\n",
    "\n",
    "#Select only two columns\n",
    "category_19_df = category_19_df.loc[:, ['Date', 'Order_Demand']]\n",
    "category_19_df['Date'] = pd.to_datetime(category_19_df['Date'])\n",
    "category_19_df['Order_Demand'] = pd.to_numeric(category_19_df['Order_Demand'], errors='coerce')\n",
    "\n",
    "# Lets remember our data structure, before we begin manipulating to predict future values:\n",
    "#print (category_19_df.head(5))\n",
    "\n",
    "#Using SciKit Learn elements, we will build and test the model\n",
    "\n",
    "# Approximating months by dividing days by average number of days per month\n",
    "category_19_df['Time'] = (category_19_df['Date'] - category_19_df['Date'].min()) / np.timedelta64(1, 'D')\n",
    "category_19_df['Time'] = category_19_df['Time'].astype(int)\n",
    "print (category_19_df.head(15))\n",
    "\n",
    "#Replace NaN values\n",
    "category_19_df = category_19_df.dropna(subset=['Order_Demand'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X = category_19_df[['Time']]\n",
    "y = category_19_df['Order_Demand']\n",
    "\n",
    "print(X.head(5))\n",
    "print(y.head(5))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the model\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE: \", rmse)\n",
    "\n",
    "# Forecast future values\n",
    "future_times = np.array([X['Time'].max() + i for i in range(1, 31)]).reshape(-1, 1)\n",
    "future_predictions = model.predict(future_times)\n",
    "future_predictions = np.round(future_predictions, 2)\n",
    "print(\"Future Predictions: \", future_predictions)\n",
    "\n",
    "# lets see how the data compares to the rest of the data:\n",
    "print (f\"mean is: {category_19_df['Order_Demand'].mean()}\")\n",
    "print (f\"median is: {category_19_df['Order_Demand'].median()}\")\n",
    "print (f\"mode is: {category_19_df['Order_Demand'].mode()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2208,
     "sourceId": 3724,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27.486904,
   "end_time": "2024-04-14T03:29:31.992746",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-14T03:29:04.505842",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
